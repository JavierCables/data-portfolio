const translations = {
  en: {
    // Main Page
    "button.language": "Spanish",
    "about.title": "ABOUT ME",
    "about.text": "As a Data Scientist, I thrive on collaborating with cross-functional teams to solve real-world problems and drive strategic decision-making through data.",
    "contact.title": "CONTACT",
    "contact.resume": "Resume",
    "contact.location": "Madrid, Spain",
    "skills.title": "SKILLS",
    "projects.title": "PROJECTS",
    "footer.thanks": "Thank you for taking the time to check out my portfolio!",

    // Projects Page
    "properties.description": "Description",
    "properties.tool": "Tool",
    "properties.projectType": "Project Type",
    "properties.link": "Link",
    "properties.data": "Data",
    "navigation.homepage": "Homepage",
    "summary.title": "Summary",
    "summary.goal.title": "Goal",
    "summary.process.title": "Process",
    "summary.insights.title": "Insights",
    "advanced.report": "Advanced Report",

    // Reports Page
    "header.report": "Detailed Report",
    "report.title": "Detailed Report — For More Information",
    "toc.title": "Table of Contents",
    "section.summary": "Project Summary",
    "section.environment": "Project Environment",
    "section.scope_steps": "Scope & Project Steps",
    "section.data_sources": "Data Sources & Data Gathering",
    "section.main_code": "Main Code",
    "sub.scope": "Scope",
    "sub.steps": "Project Steps",
    "sub.data_sources": "Data Sources",
    "sub.data_gathering": "Data Gathering",
    "sub.schema": "Schema",

    // Project: Music Clustering
    "project.title-1": "<i class='ri-music-2-fill'></i> Unsupervised Music Track Clustering",
    "properties.title-1": "Unsupervised Music Track Clustering",
    "properties.description.text-1": "AI system organizing music catalogs using <strong>unsupervised clustering</strong> on 196 acoustic features from GTZAN.",
    "summary.goal.text-1": "Develop an automated system for music organization using unsupervised learning techniques on acoustic features derived directly from audio signals. The aim was to identify intrinsic similarities between tracks, eliminating dependence on manual labels and reducing cultural biases inherent to traditional cataloging. This scalable solution contributes significantly to the <span>Music Information Retrieval</span> (MIR) field and offers practical applications for streaming platforms and recommendation systems.",
    "summary.process.text-1": "The pipeline began with curating the GTZAN dataset (999 tracks) to ensure data quality and consistency. We implemented a feature extraction pipeline to derive 196 acoustic features (including <span>MFCC</span>, <span>Chroma Frequencies</span>, <span>Spectral Centroid</span>, etc.) per track. Statistical aggregation (mean, standard deviation, percentiles) transformed temporal data into long-term statistics. Four clustering algorithms (<span>K-Means</span>, <span>DBSCAN</span>, <span>HDBSCAN</span>, <span>GMM</span>) were implemented and compared. Optimization involved systematic parameter selection for <span>DBSCAN</span> and using information criteria (BIC/AIC) for <span>GMM</span>.",
    "summary.insights.text-1": "The system successfully clustered tracks, with <span>DBSCAN</span> demonstrating superior performance, achieving a combined score of 0.563 across 18 clusters. This outcome highlights that density-based algorithms effectively capture the variable density characteristics of musical patterns. The optimized <span>Top20</span> feature subset provided the best balance between acoustic information and computational efficiency. The results confirm the viability of automatic clustering for massive music catalog organization, offering a scalable alternative to traditional label-based methods.",
    "viz.metrics.title-1": "Relationship between Evaluation Metrics (Size proportional to Combined Score)",
    "viz.heatmap.title-1": "Heatmap: Subset Performance by Metric",

    // Project: ANRP Recognition
    "project.title-2": "<i class='ri-steering-2-fill'></i> Automatic Number Plate Recognition",
    "properties.title-2": "Automatic Number Plate Recognition",
    "properties.description.text-2": "Automatic Number Plate Recognition using <strong>YOLOv8</strong>, object tracking (SORT), and <strong>EasyOCR</strong>.",
    "summary.goal.text-2": "The primary goal was to develop a robust Automatic Number Plate Recognition (<span>ANPR</span>) system using 100% <span>Python</span>. This involved accurately detecting moving license plates and reading the corresponding text in a video environment. A key aspect was combining object detection (<span>YOLOv8</span>) with object tracking (<span>SORT</span>) to assign unique IDs to vehicles throughout the video. This tracking was crucial for determining the single, most accurate license plate value for each car by selecting the read text with the highest OCR confidence score, thereby solving ambiguity issues across multiple frames. The project focused specifically on the United Kingdom license plate format.",
    "summary.process.text-2": "The process began with loading <span>YOLOv8</span> models for car and license plate detection. Frames were read and vehicles detected. Object tracking (<span>SORT</span>) was implemented on vehicles to assign unique IDs. License plates were detected and assigned to their corresponding tracked cars using bounding box containment logic. The license plate image was cropped and pre-processed using grayscale conversion and thresholding to optimize OCR performance. <span>EasyOCR</span> read the text. Post-processing involved validating the text against the UK format and correcting common character confusions (e.g., S/5, O/0) for robustness. Results, including bounding box data and confidence scores, were structured by frame and car ID, saved to a <span>CSV file</span>, and interpolated for stable video visualization.",
    "summary.insights.text-2": "The project successfully implemented a complete end-to-end Automatic Number Plate Recognition system. By integrating deep learning object detection (<span>YOLOv8</span>) and robust object tracking (<span>SORT</span>), the solution could track vehicles and reliably associate license plate detections. Critical computer vision steps were applied, including image preprocessing (<span>thresholding</span>) to maximize <span>OCR</span> accuracy. Post-processing logic ensured that only texts matching the required format were accepted and provided automatic character correction to enhance reliability. The methodology leveraged the vehicle tracking data to select the single most confident license plate reading for each vehicle over time. The final output included a structured <span>CSV file</span> containing frame-by-frame vehicle and license plate data, ready for further analysis and video visualization.",
    "information.title-2": "UK License Plate Format",
    "video.title-2.1": "Initial Data",
    "video.title-2.2": "Final Visualization",

    // Project: Medical Chatbot
    "project.title-3": "<i class='ri-heart-2-fill'></i> Medical Chatbot with Generative AI",
    "properties.title-3": "Medical Chatbot with Generative AI",
    "properties.description.text-3": "<strong>Generative AI</strong> medical chatbot (RAG) using custom data (4505-page book) and <strong>Pinecone</strong> Vector DB.",
    "summary.goal.text-3": "The primary goal was to implement a robust, production-ready, and end-to-end <span>Generative AI</span> application: a specialized medical chatbot. This required creating a <span>Retrieval-Augmented Generation</span> (<span>RAG</span>) system utilizing proprietary medical data (a large book, The G Encyclopedia of Medicine) to establish a comprehensive knowledge base. The system was designed to deliver accurate suggestions for diagnosis, medicine, and treatment, integrated with a functional user interface built using the <span>Flask</span> framework.",
    "summary.process.text-3": "The implementation followed a complete development pipeline using modular <span>Python</span> coding and the <span>LangChain</span> framework. Data was extracted from a 4505-page PDF, chunked, and transformed into over 7,000 vector embeddings using a <span>Hugging Face</span> model. These embeddings were stored in <span>Pinecone</span>, a cloud-based vector database, to establish the semantic index/knowledge base. An <span>Gemini AI LLM</span> was integrated to process user queries and contextualize ranked results from the database, delivering high-quality responses.",
    "summary.insights.text-3": "This project successfully delivered a custom <span>RAG-based</span> medical chatbot, capable of retrieving and generating detailed, context-specific medical information and suggestions based exclusively on its custom knowledge base. Key technologies utilized include <span>Python</span>, <span>LangChain</span>, <span>Pinecone Vector DB</span>, <span>Hugging Face</span> embedding models, and <span>Flask</span>. The implementation adhered to development best practices, featuring a structured folder layout, version control via <span>Git</span>/<span>GitHub</span>, and planning for future <span>LLM Ops</span> cloud deployment.",
    "video.title-3.1": "Preview",
    "video.title-3.2": "Visualization",

    // Project: Road Accident
    "project.title-4": "<i class='ri-roadster-fill'></i> Road Accident Analysis Power BI Dashboard",
    "properties.title-4": "Road Accident Analysis Power BI Dashboard",
    "properties.description.text-4": "Dynamic <strong>Power BI</strong> dashboard analyzing 2021-2022 road accident data, casualties, and trends.",
    "summary.goal.text-4": "The primary Goal was to develop a comprehensive, dynamic, and interactive Road Accident Dashboard (2021-2022) using <span>Power BI</span>. It would meet client requirements for calculating primary <span>KPIs</span> like <span>CY Casualties</span>, <span>Total Accidents</span>, and <span>YoY growth</span>. The dashboard would provide actionable insights for stakeholders (e.g., Ministry of Transport) on casualty severity, location (urban/rural), road type, and light conditions, supporting preventive decisions.",
    "summary.process.text-4": "The process involved Requirement Gathering and connecting the flat file (<span>Excel</span>) data. Raw data (307k rows) was processed in <span>Power Query Editor</span>, including Data Cleaning (e.g., correcting spelling errors like 'fetal' to 'fatal'). Data Transformation included creating a custom <span>Date Table</span> (<span>Calendar Table</span>) crucial for time intelligence functions. Data Modeling established a one-to-many relationship between the data and the calendar table. Advanced <span>DAX measures</span> were built for <span>YoY comparisons</span> and <span>YTD totals</span>. The final dashboard utilized multiple visuals (<span>KPIs</span>, <span>Area Chart</span>, <span>Map</span>) and grouping features to deliver dynamic reporting.",
    "summary.insights.text-4": "The output is a dynamic and interactive dashboard featuring essential <span>KPIs</span> and trends. Key insights showed a positive reduction: Casualties and accidents decreased by roughly <span>11-12% YoY</span>. Analysis confirmed that single carriageways (70-75%) and urban areas are major contributors to incidents. A location map identified high-risk hotspots. The dashboard uses interactive filters and a custom, aesthetically pleasing background to ensure user-friendliness and effective communication of data to stakeholders. The report is exportable to PDF.",
    "dashboard.title-4": "Final Dashboard",

    // Project: Netflix Analysis
    "project.title-5": "<i class='ri-movie-2-fill'></i> Netflix Movies and TV Shows Data Analysis",
    "properties.title-5": "Netflix Movies and TV Shows Data Analysis",
    "properties.description.text-5": "Analysis of 8,807 Netflix titles using <strong>PostgreSQL</strong>, solving 15 complex business problems.",
    "summary.goal.text-5": "The primary goal of this project was to conduct a comprehensive analysis of the Netflix movies and TV shows dataset (8,807 records) to address 15 medium to advanced business problems using advanced <span>SQL</span> techniques. The project aimed to demonstrate proficiency in database setup, data import, complex querying, and data manipulation within <span>PostgreSQL</span>. Key objectives included calculating content distributions (movies vs. TV shows), identifying top actors and countries, analyzing genre popularity, and assessing content based on specific keywords in descriptions (e.g., 'kill' or 'violence'). The final deliverable was a fully documented project published on a <span>GitHub</span> repository.",
    "summary.process.text-5": "The project began by acquiring the Netflix dataset from <span>Kaggle</span> and initially exploring the data in <span>Excel</span>. A <span>PostgreSQL</span> database was set up using <span>PG Admin 4</span>, and the table schema was meticulously defined, carefully setting appropriate data types (e.g., <span>VARCHAR</span> limits) for all 8,808 potential rows. Data import required adjustments to column lengths, specifically for the 'listed in' column, utilizing <span>DROP TABLE</span> and <span>CREATE TABLE</span> commands to resolve import errors. Advanced <span>SQL</span> queries were then developed to solve 15 business problems, employing complex techniques such as Window Functions (<span>RANK</span>), various string manipulation functions (<span>STRING_TO_ARRAY</span>, <span>UNNEST</span>, <span>SPLIT_PART</span>, <span>ILIKE</span>), date conversion (<span>TO_DATE</span>), and subqueries.",
    "summary.insights.text-5": "The project successfully analyzed 8,807 Netflix content records, providing detailed SQL-based solutions to 15 complex business questions. Key analytical findings included content distribution (6,131 movies and 2,676 TV shows) and the most common content rating (TV-MA) for both types. Geographic analysis was enhanced by using <span>UNNEST</span> and <span>STRING_TO_ARRAY</span> to accurately split multi-country entries and identify top content-producing nations (like the US and India). Functional expertise was confirmed in handling non-standard text-based dates and durations. Finally, content was categorized (as 'Bad' or 'Good') based on description keywords using a <span>CASE</span> statement, demonstrating logical filtering capabilities. The complete analytical solution was documented and published on <span>GitHub</span>.",
    "results.title-5": "Results",

    // Report: Music Clustering
    "section.acoustic_descriptors": "Fundamental Acoustic Descriptors",
    "section.implemented_algorithms": "Implemented Algorithms",
    "section.combined_metrics": "Combined Metrics (Evaluation Framework)",
    "section.summary.text-1": "AI system for automatic music clustering using unsupervised ML on 196 acoustic features (<span>MFCC</span>, <span>spectral</span>, <span>chroma</span>) extracted from GTZAN. We compared four algorithms. <span>DBSCAN</span> achieved the highest score (0.563) across 18 clusters, confirming the viability of the approach for massive, unbiased music catalog organization.",
    "section.environment.text-1": "Developed in <span>Python</span> 3.10.13 using <span>Jupyter Notebook</span>. Key libraries: <span>Librosa</span> (audio features), <span>Pandas</span>/<span>NumPy</span> (data manipulation), <span>Scikit-learn</span> (ML models), and specialized clustering libraries like <span>HDBSCAN</span>.",
    "sub.scope.text-1": "Automatic organization of music catalogs via unsupervised clustering on 196 acoustic features extracted from audio signals.",
    "sub.steps.text-1.1": "Comprehensive literature review (<span>MIR</span>, clustering, audio features)",
    "sub.steps.text-1.2": "GTZAN dataset curation and validation (999 valid samples)",
    "sub.steps.text-1.3": "Feature extraction pipeline design (196 acoustic features per track)",
    "sub.steps.text-1.4": "Implementation and optimization of four clustering models (<span>DBSCAN</span>, <span>K-Means</span>, etc.)",
    "sub.steps.text-1.5": "Evaluation using combined metrics (<span>Silhouette</span>, <span>ARI</span>, combined score)",
    "section.acoustic_descriptors.text.1": "These coefficients simulate the non-linear response of the human ear using filter banks on the Mel scale. <span>MFCCs</span> are fundamental features specifically designed to capture the timbral characteristics (spectral envelope) of the sound. They are generated by the de-correlation of Mel spectral vectors using the discrete cosine transform.",
    "section.acoustic_descriptors.text.2": "A 12-dimensional vector representation that displays the relative intensity in each of the twelve semitones of a chromatic scale. These features are crucial for representing the harmonic content and tonal structure of the music, demonstrating robustness against timbre variations.",
    "section.acoustic_descriptors.text.3": "This feature represents the 'center of gravity' of the spectrum, which is directly related to auditory brightness. Higher values of the spectral centroid indicate that the signal's energy is more concentrated in higher frequencies.",
    "section.acoustic_descriptors.text.4": "Defined as the frequency below which a specified proportion (typically 85-95%) of the total spectral energy is accumulated. It provides valuable information on the energy distribution across frequencies and is used to distinguish between harmonic and noisy sounds.",
    "section.acoustic_descriptors.text.5": "Quantifies the number of times the audio signal crosses the zero amplitude level within a specified temporal window. <span>ZCR</span> contributes information about the textural characteristics of the signal and is highly sensitive to 'noise' in the audio; higher noise tends to increase the <span>ZCR</span> value.",
    "section.implemented_algorithms.text": "The project implemented and optimized multiple clustering algorithms adapted specifically for the musical domain:",
    "section.implemented_algorithms.text.1": "Implemented with specific optimizations, including <span>K-Means++</span> initialization to improve convergence and reduce sensitivity to random starting points. The elbow method and silhouette analysis were used to determine the optimal number of clusters (k). K-Means showed consistency and stability across configurations, with an average performance of 0.420 on the combined score.",
    "section.implemented_algorithms.text.2-1": "Configured to identify clusters of variable density, a characteristic particularly useful for detecting musical subgenres and atypical patterns. Systematic optimization of the parameters epsilon (ϵ) and MinPts was performed using grid search.",
    "section.implemented_algorithms.text.2-2": "Key Finding: <span>DBSCAN</span> emerged as the most effective algorithm, achieving the highest combined score of 0.563 with 18 clusters. This superiority suggests that musical patterns exhibit variable density characteristics which are better captured by density-based algorithms than by traditional centroidal methods.",
    "section.implemented_algorithms.text.3": "Implemented as a hierarchical extension of <span>DBSCAN</span>. <span>HDBSCAN</span> allows for the automatic identification of clusters with variable densities, eliminating the need to specify the ϵ parameter. HDBSCAN achieved the second-best result with a combined score of 0.458 (generating 5 clusters).",
    "section.implemented_algorithms.text.4": "Implemented to model clusters with complex Gaussian shapes. <span>GMM</span> included the capability for automatic determination of the number of components using Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC).",
    "section.combined_metrics.text.1": "A comprehensive evaluation framework was established to quantify the quality of the musical clustering from multiple perspectives, combining traditional clustering metrics with domain-specific evaluations. This framework resulted in a Combined Score, designed to balance internal coherence (quality) with external correspondence (relevance).",
    "section.combined_metrics.text.2": "The combined score is calculated using the following weighted formula:",
    "section.combined_metrics.text.3": "Where:",
    "section.combined_metrics.text.4": "sil (<span>Silhouette Score</span>): A metric of intrinsic quality that measures how well each data point is assigned to its own cluster and separated from neighboring clusters. It accounts for 40% of the total score. Scores range from -1 to +1, where values close to +1 indicate a span assignment.",
    "section.combined_metrics.text.5": "ari (<span>Adjusted Rand Index</span>): An extrinsic metric that measures the similarity between the resulting clustering assignments and the actual known musical genres (the real labels of the GTZAN dataset). It accounts for 30% of the total score. ARI values range between -0.5 and 1.0, with 1.0 indicating perfect clustering.",
    "section.combined_metrics.text.6": "k_pen (K-Penalty Factor): A factor based on the number of clusters (k_pen=n_clust/target_k) that contributes to the adequacy of the number of clusters. It accounts for 30% of the total score.",
    "section.combined_metrics.text.7": "This weighted combination provides an integral evaluation that captures both the internal coherence of the musical clusters and their correspondence with established genre categories, making it especially valuable for automatic analysis of large music catalogs. <span>DBSCAN</span> achieved the highest combined evaluation score of 0.563 with this framework.",    
  
    // Report: ANPR Recognition
    "section.summary.text-2": "Developed a 100% <span>Python</span> <span>ANPR</span> pipeline for video footage. Integrated <span>YOLOv8</span> for car/plate detection, <span>SORT</span> for vehicle tracking, and <span>EasyOCR</span> for robust text recognition. The system assigns unique car IDs across frames and resolves license plate ambiguity by selecting the text with the highest <span>OCR confidence score</span>.",
    "section.environment.text-2": "The environment is 100% <span>Python</span>. Key tools include the <span>YOLOv8</span> object detector (<span>Ultralytics</span>), the <span>SORT</span> object tracking algorithm, and the <span>EasyOCR</span> library for text recognition. Image processing utilized <span>OpenCV</span> (<span>CV2</span>).",
    "sub.scope.text-2": "End-to-end <span>ANPR</span> system focused on detecting, tracking, and reading UK license plates (<span>LLNNLLL</span>) in highway video.",
    "sub.steps.text-2.1": "Load two <span>YOLOv8</span> models: one for car detection (<span>COCO</span>) and one for license plate detection",
    "sub.steps.text-2.2": "Read video frames sequentially and detect vehicles using the <span>COCO</span> model",
    "sub.steps.text-2.3": "Implement <span>SORT</span> object tracking to assign unique, persistent IDs to detected vehicles",
    "sub.steps.text-2.4": "Detect license plates and associate each plate bounding box with its respective tracked car",
    "sub.steps.text-2.5": "Crop the plate image and apply preprocessing: grayscale conversion and thresholding",
    "sub.steps.text-2.6": "Read text using <span>EasyOCR</span>; validate and correct common character confusions (e.g., S/5, O/0)",
    "sub.steps.text-2.7": "Structure results (ID, bounding box, text, scores) into a dictionary keyed by frame number",
    "sub.steps.text-2.8": "Write the complete structured results to a <span>CSV</span> output file for storage and visualization",
    "sub.data_sources.text-2": "Primary data is a highway video with many cars, featuring a very frontal view of the vehicles and license plates. The license plate detector model was trained externally using a linked dataset.",
    "sub.data_gathering.text-2.1": "Data was gathered from an input video file (<span>sample.mp4</span>) by reading frames sequentially using <span>OpenCV</span>/<span>CV2</span>. Two separate object detection models were used per frame: A pre-trained <span>COCO</span> model was utilized to detect general vehicles (such as cars, buses, and trucks), and a custom-trained <span>YOLOv8</span> model was used to detect the license plates specifically.",
    "sub.data_gathering.text-2.2": "The <span>SORT</span> algorithm was applied to the vehicle detections to gather persistent tracking data, assigning unique car IDs that identify the vehicle across multiple frames.",
    "sub.data_gathering.text-2.3": "For license plate text, the plate image was cropped, pre-processed (converted to grayscale and thresholded) to simplify the image, and then the text and confidence score were gathered using the <span>EasyOCR</span> library. This raw detection and <span>OCR</span> data were then filtered for vehicles, associated with a car ID, validated against the specific UK format (two letters, two numbers, three letters), and structured into a dictionary keyed by the frame number before final output to a <span>CSV file</span>. Missing bounding box data in frames where the license plate was not successfully read was handled via external data interpolation to ensure stable visualization.",  

    // Report: Medical Chatbot
    "section.summary.text-3": "Implemented an end-to-end medical chatbot utilizing a <span>Retrieval-Augmented Generation</span> (<span>RAG</span>) pipeline and proprietary data (The G Encyclopedia of Medicine). The system provides suggestions for diagnosis, medicine, and treatment. Built using modular <span>Python</span>, <span>LangChain</span>, <span>Pinecone Vector DB</span>, and integrated with a functional <span>Flask</span> UI.",
    "section.environment.text-3": "<span>Python</span> (modular coding), <span>LangChain</span> (generative framework), <span>Pinecone</span> (Cloud-based Vector DB), <span>Gemini AI LLM</span>, <span>Hugging Face</span> (Embedding Models, 384 dimensions), <span>Flask</span> (UI), <span>Git</span>/<span>GitHub</span> (version control), <span>PyPDFLoader</span>, and recursive text splitter were utilized.",
    "sub.scope.text-3": "Developed <span>RAG</span> system using <span>Python</span>, <span>LangChain</span>, <span>Pinecone</span>, <span>Gemini AI</span>, <span>Hugging Face</span>, and <span>Flask</span> for medical suggestions.",
    "sub.steps.text-3.1": "Established a <span>Python</span> virtual environment and set up necessary dependencies listed in requirements.txt",
    "sub.steps.text-3.2": "Created a robust, modular folder structure to maintain an organized and scalable code base",
    "sub.steps.text-3.3": "Extracted all document contents from the medical PDF using the <span>PyPDFLoader",
    "sub.steps.text-3.4": "The extracted text was split into 7,020 chunks (size 500, overlap 20) using a text splitter",
    "sub.steps.text-3.5": "A <span>Hugging Face</span> embedding model was used to convert text chunks into 384-dimensional vectors",
    "sub.steps.text-3.6": "The vectors were stored in a cloud-based <span>Pinecone Vector DB</span> to create the knowledge base/semantic index",
    "sub.steps.text-3.7": "Initialized the <span>GeminiAI LLM</span> and linked it with the <span>Pinecone</span> index using the <span>RAG</span> chain",
    "sub.steps.text-3.8": "Developed a functional and visually appealing front-end user interface using <span>Flask</span> (<span>Python</span> framework), <span>HTML</span>, <span>CSS</span> and <span>JavaScript</span>",
    "sub.steps.text-3.9": "Implemented the application endpoint (<span>app.py</span>) for production readiness and cloud deployment planning",
    "sub.data_sources.text-3": "The custom dataset source is The G Encyclopedia of Medicine (4505-page PDF). It contains comprehensive medical information including diseases, diagnoses, treatments, and medicine suggestions.",
    "sub.data_gathering.text-3.1": "The custom data used for the project was obtained from an entire medical book, specifically The G Encyclopedia of Medicine, which is available as a PDF document spanning approximately 4505 pages. This proprietary dataset contains exhaustive medical information regarding all kinds of disease, diagnosis techniques, appropriate treatment plans, and suggested medicine.",
    "sub.data_gathering.text-3.2": "The first step in data gathering and ingestion involved loading the PDF document using the <span>PyPDFLoader</span> utility from <span>LangChain</span>. Once the entire content was extracted, the data needed to be prepared for the <span>Large Language Model</span> (<span>LLM</span>), requiring a chunking operation due to the <span>LLM</span>'s fixed input size limitations.",
    "sub.data_gathering.text-3.3": "A recursive character text splitter was employed to break the extracted text into smaller, manageable text chunks. This process generated a total of 7,020 chunks from the original document. These chunks were then converted into 384-dimensional vector embeddings using an open-source model from the <span>Hugging Face</span> platform. Finally, these embeddings were stored in <span>Pinecone</span>, a cloud-based vector database, which serves as the permanent and scalable knowledge base for the <span>RAG</span> system.",

    // Report: Road Accident
    "section.data_modeling": "Data Modeling, Measures and Schema",
    "section.summary.text-4": "This project focused on developing a dynamic and interactive <span>Power BI</span> dashboard from start to finish for Road Accident Analysis. The primary objective was to leverage road accident data for 2021 and 2022 to derive critical insights. The dashboard was designed to meet specific client requirements, including calculating Primary <span>KPIs</span> such as total casualties, total accidents, and year-on-year growth. Secondary <span>KPIs</span> involved analyzing casualties based on severity (fatal, serious, slight), vehicle types, road types, area locations (urban/rural), and light conditions (day/night). The visualization also aimed to identify accident hotspots by location.",
    "section.environment.text-4": "This project used only the Free Version of <span>Power BI</span>.",
    "sub.scope.text-4": "End-to-end development of an interactive dashboard using <span>Power BI</span>, <span>Power Query</span>, and <span>DAX</span> to analyze two years of road accident data.",
    "sub.steps.text-4.1": "Connected raw <span>Excel</span> data (307k rows) to <span>Power BI Desktop",
    "sub.steps.text-4.2": "Cleaned data in <span>Power Query Editor</span> by correcting typographical errors (e.g., replacing 'fetal' with 'fatal')",
    "sub.steps.text-4.3": "Created a custom <span>Calendar Table</span> using <span>DAX</span> for <span>Time Intelligence</span> functions",
    "sub.steps.text-4.4": "Established a one-to-many relationship between the <span>Calendar Table</span> and the main data table",
    "sub.steps.text-4.5": "Wrote complex <span>DAX</span> measures for <span>Current Year</span> (<span>YTD</span>), <span>Previous Year</span>, and <span>Year-on-Year</span> growth calculations",
    "sub.steps.text-4.6": "Built and formatted various visualizations (<span>KPI cards</span>, <span>Area Chart</span>, <span>Donut Charts</span>, <span>Bar Chart</span> and <span>Map</span>)",
    "sub.steps.text-4.7": "Implemented <span>Slicers</span> (Road Surface, Weather Conditions) for dynamic filtering",
    "sub.data_sources.text-4": "The raw data utilized for this project was an <span>Excel</span> file. This file served as the database, containing approximately 307,000 rows and 21 columns.",
    "sub.data_gathering.text-4": "The <span>Excel</span> can be seen in <a href='https://www.data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-accidents-safety-data'>Road Safety Data</a>.",
    "sub.data_modeling": "Data Modeling",
    "sub.dax_measures": "DAX Measures",

    // Report: Netflix Analysis
    "section.solutions": "Solutions", 
    "section.summary.text-5": "Advanced <span>SQL</span> analysis of 8,807 Netflix titles, solving 15 complex business problems. The methodology involved setting up a <span>PostgreSQL</span> database, defining the schema, manipulating complex text fields using array and string functions (<span>UNNEST</span>, <span>STRING_TO_ARRAY</span>), and applying Window Functions.",
    "section.environment.text-5": "The core tools used were <span>PostgreSQL</span> for the database and querying, with <span>PG Admin 4</span> serving as the management interface. Initial data inspection was conducted in <span>Excel</span>. The final project was published on <span>GitHub</span>.",
    "sub.scope.text-5": "Solve 15 medium-to-advanced business problems using complex <span>SQL</span> queries on 8,807 Netflix records.",
    "sub.steps.text-5.1": "Acquired the 'Netflix movies and TV shows' dataset from the <span>Kaggle</span> platform",
    "sub.steps.text-5.2": "Performed initial data exploration in <span>Excel</span> to verify column types and lengths",
    "sub.steps.text-5.3": "Created the database and defined the table schema in <span>PostgreSQL</span> using <span>PG Admin 4</span>",
    "sub.steps.text-5.4": "Defined precise data types, calculating <span>VARCHAR</span> limits for long text columns",
    "sub.steps.text-5.5": "Imported the data, addressing import failures by correcting the <span>VARCHAR</span> length",
    "sub.steps.text-5.6": "Confirmed successful import, verifying the existence of 8,807 total records",
    "sub.steps.text-5.7": "Developed complex <span>SQL</span> solutions for 15 specified business problems",
    "sub.steps.text-5.8": "Used advanced techniques like <span>UNNEST</span> to split multi-value columns (countries, cast)",
    "sub.steps.text-5.9": "Published the documented project and code solutions on a <span>GitHub</span> repository",
    "sub.data_sources.text-5": "The dataset, titled 'Netflix movies and TV shows' was downloaded from <span>Kaggle</span>. It contains 8,808 records (titles) with details on show ID, type (movie/TV show), director, cast, country, release date, rating, duration, genre, and descriptions.",
    "sub.data_gathering.text-5.1": "The data gathering process began with locating and downloading the required dataset, 'Netflix movies and TV shows' from the <span>Kaggle</span> website. This dataset was provided as a compressed (zipped) file, which was then unzipped. Link <a href='https://www.kaggle.com/datasets/shivamb/netflix-shows'>[HERE]</a>.",
    "sub.data_gathering.text-5.2": "Following the download, the file was opened in <span>Excel</span> for a critical initial exploration. This phase was essential for inspecting the characteristics of the data, especially the potential lengths of text fields such as title, director, cast, and descriptions. The check revealed that certain columns contained extremely long character strings (e.g., director up to 208 characters, cast up to 771 characters, and description up to 250 characters), which directly influenced the subsequent database schema design. The dataset was confirmed to have a total of 8,808 rows.",
    "sub.data_gathering.text-5.3": "The next step involved setting up the target database in <span>PostgreSQL</span> and defining the table structure. During schema creation, appropriate <span>VARCHAR</span> limits were set for all columns based on the <span>Excel</span> analysis to prevent truncation errors. Subsequently, the data was imported into the <span>PostgreSQL</span> environment via <span>PG Admin 4</span>. An initial import attempt failed due to an insufficient <span>VARCHAR</span> limit defined for the 'listed in' (genre) column. This was resolved by using the <span>DROP TABLE</span> command, increasing the column limit (from 25 to 100 characters), recreating the table, and re-running the import process successfully. This ensured the availability of all 8,807 final records for analysis.",
    "sub.solution.code": "Code",
    "sub.solution.result": "Result",
    "sub.solution.title-5.1": "1. Count the number of Movies vs TV Shows",
    "sub.solution.title-5.2": "2. Find the most common rating for movies and TV shows",
    "sub.solution.title-5.3": "3. List all movies released in a specific year (e.g., 2020)",
    "sub.solution.title-5.4": "4. Find the top 5 countries with the most content on Netflix",
    "sub.solution.title-5.5": "5. Identify the longest movie",
    "sub.solution.title-5.6": "6. Find content added in the last 5 years",
    "sub.solution.title-5.7": "7. Find all the movies/TV shows by director 'Rajiv Chilaka'",
    "sub.solution.title-5.8": "8. List all TV shows with more than 5 seasons",
    "sub.solution.title-5.9": "9. Count the number of content items in each genre",
    "sub.solution.title-5.10": "10. Find each year and the average numbers of content release in India on netflix. return top 5 year with highest avg content release",
    "sub.solution.title-5.11": "11. List all movies that are documentaries",
    "sub.solution.title-5.12": "12. Find all content without a director",
    "sub.solution.title-5.13": "13. Find how many movies actor 'Salman Khan' appeared in last 10 years",
    "sub.solution.title-5.14": "14. Find the top 10 actors who have appeared in the highest number of movies produced in India",
    "sub.solution.title-5.15": "15. Categorize the content based on the presence of the keywords 'kill' and 'violence' in the description field. Label content containing these keywords as 'Bad' and all other content as 'Good'. Count how many items fall into each category",
  },

  es: {
    // Página principal
    "button.language": "English",
    "about.title": "SOBRE MÍ",
    "about.text": "Como científico de datos, disfruto colaborando con equipos multidisciplinares para resolver problemas reales y apoyar la toma de decisiones estratégicas basadas en datos.",
    "contact.title": "CONTACTO",
    "contact.resume": "Currículum",
    "contact.location": "Madrid, España",
    "skills.title": "HABILIDADES",
    "projects.title": "PROYECTOS",
    "footer.thanks": "¡Gracias por tomarte el tiempo de revisar mi portfolio!",  

    // Página proyectos
    "properties.description": "Descripción",
    "properties.tool": "Herramientas",
    "properties.projectType": "Tipo de proyecto",
    "properties.link": "Enlace",
    "properties.data": "Datos",
    "navigation.homepage": "Inicio",
    "summary.title": "Resumen",
    "summary.goal.title": "Objetivo",
    "summary.process.title": "Proceso",
    "summary.insights.title": "Conclusiones",
    "advanced.report": "Informe avanzado",

    // Página de informes
    "header.report": "Informe detallado",
    "report.title": "Informe detallado — Para más información",
    "toc.title": "Tabla de contenidos",
    "section.summary": "Resumen del proyecto",
    "section.environment": "Entorno del proyecto",
    "section.scope_steps": "Alcance y Pasos del proyecto",
    "section.data_sources": "Fuentes de datos y Recolección",
    "section.main_code": "Código principal",
    "sub.scope": "Alcance",
    "sub.steps": "Pasos del proyecto",
    "sub.data_sources": "Fuentes de datos",
    "sub.data_gathering": "Recolección de datos",
    "sub.schema": "Esquema",

    // Proyecto: Music Clustering
    "project.title-1": "<i class='ri-music-2-fill'></i> Clustering no supervisado de pistas musicales",
    "properties.title-1": "Clustering no supervisado de pistas musicales",
    "properties.description.text-1": "Sistema de IA que organiza catálogos musicales usando <strong>clustering no supervisado</strong> sobre 196 características acústicas del dataset GTZAN.",
    "summary.goal.text-1": "Desarrollar un sistema automatizado para la organización musical utilizando técnicas de aprendizaje no supervisado sobre características acústicas derivadas directamente de señales de audio. El objetivo era identificar similitudes intrínsecas entre pistas, eliminando la dependencia de etiquetas manuales y reduciendo los sesgos culturales inherentes a la catalogación tradicional. Esta solución escalable contribuye significativamente al campo de la <span>recuperación de información musical</span> (MIR) y ofrece aplicaciones prácticas para plataformas de streaming y sistemas de recomendación.",
    "summary.process.text-1": "El pipeline comenzó con la selección del conjunto de datos GTZAN (999 pistas) para garantizar la calidad y la coherencia de los datos. Implementamos un proceso de extracción de características para obtener 196 características acústicas (entre ellas, <span>MFCC</span>, <span>Chroma Frequencies</span>, <span>Spectral Centroid</span>, etc.) por pista. La agregación estadística (media, desviación estándar, percentiles) transformó los datos temporales en estadísticas a largo plazo. Se implementaron y compararon cuatro algoritmos de agrupamiento (<span>K-Means</span>, <span>DBSCAN</span>, <span>HDBSCAN</span>, <span>GMM</span>). La optimización implicó la selección sistemática de parámetros para <span>DBSCAN</span> y el uso de criterios de información (BIC/AIC) para <span>GMM</span>.",
    "summary.insights.text-1": "El sistema agrupó correctamente las pistas, y <span>DBSCAN</span> demostró un rendimiento superior, con una puntuación combinada de 0,563 en 18 grupos. Este resultado resalta que los algoritmos basados en la densidad captan eficazmente las características de densidad variable de los patrones musicales. El subconjunto de características optimizado <span>Top20</span> proporcionó el mejor equilibrio entre la información acústica y la eficiencia computacional. Los resultados confirman la viabilidad de la agrupación automática para la organización de catálogos musicales masivos, ofreciendo una alternativa escalable a los métodos tradicionales basados en etiquetas.",
    "viz.metrics.title-1": "Relación entre métricas de evaluación (Tamaño proporcional al Combined Score)",
    "viz.heatmap.title-1": "Heatmap: Rendimiento por métrica",

    // Proyecto: ANRP Recognition
    "project.title-2": "<i class='ri-steering-2-fill'></i> Reconocimiento automático de matrículas",
    "properties.title-2": "Reconocimiento automático de matrículas",
    "properties.description.text-2": "Reconocimiento automático de matrículas mediante <strong>YOLOv8</strong>, seguimiento de objetos (SORT) y <strong>EasyOCR</strong>.",
    "summary.goal.text-2": "El objetivo principal era desarrollar un sistema robusto de reconocimiento automático de matrículas (<span>ANPR</span>) utilizando 100 % <span>Python</span>. Esto implicaba detectar con precisión las matrículas en movimiento y leer el texto correspondiente en un entorno de vídeo. Un aspecto clave fue combinar la detección de objetos (YOLOv8) con el seguimiento de objetos (SORT) para asignar identificadores únicos a los vehículos a lo largo del vídeo. Este seguimiento fue crucial para determinar el valor único y más preciso de la matrícula de cada coche, seleccionando el texto leído con la puntuación de confianza OCR más alta, resolviendo así los problemas de ambigüedad en múltiples fotogramas. El proyecto se centró específicamente en el formato de las matrículas del Reino Unido.",
    "summary.process.text-2": "El proceso comenzó con la carga de modelos <span>YOLOv8</span> para la detección de automóviles y matrículas. Se leyeron los fotogramas y se detectaron los vehículos. Se implementó el seguimiento de objetos (<span>SORT</span>) en los vehículos para asignarles identificadores únicos. Se detectaron las matrículas y se asignaron a los automóviles correspondientes mediante la lógica de contención de cuadros delimitadores. La imagen de la matrícula se recortó y se preprocesó mediante conversión a escala de grises y umbralización para optimizar el rendimiento del OCR. <span>EasyOCR</span> leyó el texto. El posprocesamiento consistió en validar el texto según el formato del Reino Unido y corregir las confusiones de caracteres comunes (por ejemplo, S/5, O/0) para mayor solidez. Los resultados, incluidos los datos del cuadro delimitador y las puntuaciones de confianza, se estructuraron por fotograma e identificación del coche, se guardaron en un <span>archivo CSV</span> y se interpolaron para una visualización estable del vídeo.",
    "summary.insights.text-2": "El proyecto implementó con éxito un sistema completo de reconocimiento automático de matrículas de principio a fin. Mediante la integración de la detección de objetos mediante aprendizaje profundo (<span>YOLOv8</span>) y el seguimiento robusto de objetos (<span>SORT</span>), la solución podía rastrear vehículos y asociar de forma fiable las detecciones de matrículas. Se aplicaron pasos críticos de visión artificial, incluido el preprocesamiento de imágenes (<span>umbralización</span>) para maximizar la precisión del <span>OCR</span>. La lógica de posprocesamiento garantizó que solo se aceptaran los textos que coincidieran con el formato requerido y proporcionó una corrección automática de caracteres para mejorar la fiabilidad. La metodología aprovechó los datos de seguimiento de vehículos para seleccionar la lectura de matrícula más fiable para cada vehículo a lo largo del tiempo. El resultado final incluía un <span>archivo CSV</span> estructurado que contenía datos fotograma a fotograma del vehículo y la matrícula, listos para su posterior análisis y visualización en vídeo.",
    "information.title-2": "Formato de matrícula del Reino Unido",
    "video.title-2.1": "Datos iniciales",
    "video.title-2.2": "Visualización final",

    // Proyecto: Medical Chatbot
    "project.title-3": "<i class='ri-heart-2-fill'></i> Chatbot médico con IA generativa",
    "properties.title-3": "Chatbot médico con IA generativa",
    "properties.description.text-3": "Chatbot médico con <strong>IA generativa</strong> (RAG) que utiliza datos personalizados (libro de 4505 páginas) y la base de datos vectorial <strong>Pinecone</strong>.",
    "summary.goal.text-3": "El objetivo principal era implementar una aplicación de <span>IA generativa</span> robusta, lista para la producción y de extremo a extremo: un chatbot médico especializado. Para ello, fue necesario crear un sistema de <span>Retrieval-Augmented Generation</span> (<span>RAG</span>) que utilizara datos médicos propios (un libro de gran tamaño, The G Encyclopedia of Medicine) para establecer una base de conocimientos completa. El sistema se diseñó para ofrecer sugerencias precisas sobre diagnósticos, medicamentos y tratamientos, integrado con una interfaz de usuario funcional creada con el marco <span>Flask</span>.",
    "summary.process.text-3": "La implementación siguió un proceso de desarrollo completo utilizando programación modular en <span>Python</span> y el marco <span>LangChain</span>. Los datos se extrajeron de un PDF de 4505 páginas, se dividieron en fragmentos y se transformaron en más de 7000 incrustaciones vectoriales utilizando un modelo <span>Hugging Face</span>. Estas incrustaciones se almacenaron en <span>Pinecone</span>, una base de datos vectorial basada en la nube, para establecer el índice semántico/base de conocimientos. Se integró un <span>Gemini AI LLM</span> para procesar las consultas de los usuarios y contextualizar los resultados clasificados de la base de datos, proporcionando respuestas de alta calidad.",
    "summary.insights.text-3": "Este proyecto ha dado como resultado un chatbot médico personalizado basado en RAG, capaz de recuperar y generar información médica detallada y específica para cada contexto, así como sugerencias basadas exclusivamente en su base de conocimientos personalizada. Las tecnologías clave utilizadas incluyen <span>Python</span>, <span>LangChain</span>, <span>Pinecone Vector DB</span>, modelos de incrustación <span>Hugging Face</span> y <span>Flask</span>. La implementación se ajustó a las mejores prácticas de desarrollo, con una estructura de carpetas organizada, control de versiones mediante <span>Git</span>/<span>GitHub</span> y planificación para la futura implementación en la nube de <span>LLM Ops</span>.",
    "video.title-3.1": "Vista previa",
    "video.title-3.2": "Visualización",

    // Proyecto: Road Accident
    "project.title-4": "<i class='ri-roadster-fill'></i> Power BI Dashboard para el análisis de accidentes de tráfico",
    "properties.title-4": "Power BI Dashboard para el análisis de accidentes de tráfico",
    "properties.description.text-4": "Dashboard dinámico de <strong>Power BI</strong> que analiza los datos, las víctimas y las tendencias de los accidentes de tráfico entre 2021 y 2022.",
    "summary.goal.text-4": "El objetivo principal era desarrollar un panel de control de accidentes de tráfico (2021-2022) completo, dinámico e interactivo utilizando <span>Power BI</span>. Este cumpliría los requisitos del cliente para calcular los principales <span>KPI</span>, como <span>víctimas mortales en el año civil</span>, <span>total de accidentes</span> y <span>crecimiento interanual</span>. El panel proporcionaría información útil a las partes interesadas (por ejemplo, el Ministerio de Transporte) sobre la gravedad de las víctimas, la ubicación (urbana/rural), el tipo de carretera y las condiciones de iluminación, lo que facilitaría la toma de decisiones preventivas.",
    "summary.process.text-4": "El proceso consistió en recopilar los requisitos y conectar los datos del archivo plano (<span>Excel</span>). Los datos sin procesar (307 000 filas) se procesaron en <span>Power Query Editor</span>, incluyendo la limpieza de datos (por ejemplo, corrigiendo errores ortográficos como «fetal» por «fatal»). La transformación de datos incluyó la creación de una <span>Date Table</span> (<span>Calendar Table</span>) personalizada, fundamental para las funciones de inteligencia temporal. El modelado de datos estableció una relación uno a muchos entre los datos y la tabla de calendario. Se crearon medidas DAX avanzadas para comparaciones interanuales y totales acumulados del año. El panel final utilizó múltiples elementos visuales (KPI, gráfico de área, mapa) y funciones de agrupación para ofrecer informes dinámicos.",
    "summary.insights.text-4": "El resultado es un panel dinámico e interactivo que muestra los <span>KPI</span> y las tendencias esenciales. Los datos clave mostraron una reducción positiva: las víctimas y los accidentes disminuyeron aproximadamente un <span>11-12 % interanual</span>. El análisis confirmó que las carreteras de un solo carril (70-75 %) y las zonas urbanas son los principales factores que contribuyen a los incidentes. Un mapa de ubicación identificó los puntos críticos de alto riesgo. El panel utiliza filtros interactivos y un fondo personalizado y estéticamente agradable para garantizar la facilidad de uso y la comunicación eficaz de los datos a las partes interesadas. El informe se puede exportar a PDF.",
    "dashboard.title-4": "Dashboard final",

    // Proyecto: Netflix Analysis
    "project.title-5": "<i class='ri-movie-2-fill'></i> Análisis de datos de películas y series de Netflix",
    "properties.title-5": "Análisis de datos de películas y series de Netflix",
    "properties.description.text-5": "Análisis de 8807 títulos de Netflix utilizando <strong>PostgreSQL</strong>, resolviendo 15 problemas empresariales complejos.",
    "summary.goal.text-5": "El objetivo principal de este proyecto era realizar un análisis exhaustivo del conjunto de datos de películas y series de televisión de Netflix (8807 registros) para abordar 15 problemas empresariales de nivel medio a avanzado utilizando técnicas avanzadas de <span>SQL</span>. El proyecto tenía como objetivo demostrar la competencia en la configuración de bases de datos, la importación de datos, la realización de consultas complejas y la manipulación de datos dentro de <span>PostgreSQL</span>. Entre los objetivos clave se incluían el cálculo de la distribución de contenidos (películas frente a series de televisión), la identificación de los actores y países más populares, el análisis de la popularidad de los géneros y la evaluación de los contenidos en función de palabras clave específicas en las descripciones (por ejemplo, 'matar' o 'violencia'). El resultado final fue un proyecto completamente documentado y publicado en un repositorio de <span>GitHub</span>.",
    "summary.process.text-5": "El proyecto comenzó con la adquisición del conjunto de datos de Netflix de <span>Kaggle</span> y la exploración inicial de los datos en <span>Excel</span>. Se configuró una base de datos <span>PostgreSQL</span> utilizando <span>PG Admin 4</span> y se definió meticulosamente el esquema de la tabla, estableciendo cuidadosamente los tipos de datos adecuados (por ejemplo, los límites <span>VARCHAR</span>) para las 8808 filas potenciales. La importación de datos requirió ajustes en la longitud de las columnas, concretamente en la columna 'listed in', utilizando los comandos <span>DROP TABLE</span> y <span>CREATE TABLE</span> para resolver los errores de importación. A continuación, se desarrollaron consultas <span>SQL</span> avanzadas para resolver 15 problemas empresariales, empleando técnicas complejas como funciones de ventana (<span>RANK</span>), diversas funciones de manipulación de cadenas (<span>STRING_TO_ARRAY</span>, <span>UNNEST</span>, <span>SPLIT_PART</span>, <span>ILIKE</span>), conversión de fechas (<span>TO_DATE</span>) y subconsultas.",
    "summary.insights.text-5": "El proyecto analizó con éxito 8.807 registros de contenido de Netflix, proporcionando soluciones detalladas basadas en SQL a 15 complejas cuestiones empresariales. Entre los principales resultados analíticos se incluyen la distribución de contenidos (6131 películas y 2676 programas de televisión) y la clasificación de contenidos más común (TV-MA) para ambos tipos. El análisis geográfico se mejoró mediante el uso de <span>UNNEST</span> y <span>STRING_TO_ARRAY</span> para dividir con precisión las entradas de varios países e identificar los principales países productores de contenidos (como Estados Unidos y la India). Se confirmó la experiencia funcional en el manejo de fechas y duraciones no estándar basadas en texto. Por último, el contenido se clasificó (como 'malo' o 'bueno') en función de las palabras clave de la descripción utilizando una instrucción <span>CASE</span>, lo que demostró las capacidades de filtrado lógico. La solución analítica completa se documentó y publicó en <span>GitHub</span>.",
    "results.title-5": "Resultados",

    // Informe: Music Clustering
    "section.acoustic_descriptors": "Descriptores acústicos fundamentales",
    "section.implemented_algorithms": "Algoritmos implementados",
    "section.combined_metrics": "Métricas combinadas (marco de evaluación)",
    "section.summary.text-1": "Sistema de IA para la agrupación automática de música mediante aprendizaje automático no supervisado en 196 características acústicas (<span>MFCC</span>, <span>spectral</span>, <span>chroma</span>) extraídas de GTZAN. Comparamos cuatro algoritmos. <span>DBSCAN</span> obtuvo la puntuación más alta (0,563) en 18 clústeres, lo que confirma la viabilidad del enfoque para la organización masiva e imparcial de catálogos musicales.",
    "section.environment.text-1": "Desarrollado en <span>Python</span> 3.10.13 utilizando <span>Jupyter Notebook</span>. Bibliotecas clave: <span>Librosa</span> (funciones de audio), <span>Pandas</span>/<span>NumPy</span> (manipulación de datos), <span>Scikit-learn</span> (modelos de aprendizaje automático) y bibliotecas de agrupamiento especializadas como <span>HDBSCAN</span>.",
    "sub.scope.text-1": "Organización automática de catálogos musicales mediante agrupamiento no supervisado de 196 características acústicas extraídas de señales de audio.",
    "sub.steps.text-1.1": "Revisión bibliográfica exhaustiva (<span>MIR</span>, agrupamiento, características de audio)",
    "sub.steps.text-1.2": "Curación y validación del conjunto de datos GTZAN (999 muestras válidas)",
    "sub.steps.text-1.3": "Diseño del pipeline de extracción de características (196 características acústicas por pista)",
    "sub.steps.text-1.4": "Implementación y optimización de cuatro modelos de agrupamiento (<span>DBSCAN</span>, <span>K-Means</span>, etc.)",
    "sub.steps.text-1.5": "Evaluación mediante métricas combinadas (<span>Silhouette</span>, <span>ARI</span>, puntuación combinada)",
    "section.acoustic_descriptors.text.1": "Estos coeficientes simulan la respuesta no lineal del oído humano utilizando bancos de filtros en la escala Mel. Las <span>MFCC</span> son características fundamentales diseñadas específicamente para capturar las características tímbricas (envolvente espectral) del sonido. Se generan mediante la decorrelación de vectores espectrales Mel utilizando la transformada coseno discreta.",
    "section.acoustic_descriptors.text.2": "Una representación vectorial de 12 dimensiones que muestra la intensidad relativa en cada uno de los doce semitonos de una escala cromática. Estas características son cruciales para representar el contenido armónico y la estructura tonal de la música, demostrando solidez frente a las variaciones de timbre.",
    "section.acoustic_descriptors.text.3": "Esta característica representa el 'centro de gravedad' del espectro, que está directamente relacionado con el brillo auditivo. Los valores más altos del centroide espectral indican que la energía de la señal está más concentrada en las frecuencias más altas.",
    "section.acoustic_descriptors.text.4": "Se define como la frecuencia por debajo de la cual se acumula una proporción específica (normalmente entre el 85 % y el 95 %) de la energía espectral total. Proporciona información valiosa sobre la distribución de la energía entre las frecuencias y se utiliza para distinguir entre sonidos armónicos y ruidosos.",
    "section.acoustic_descriptors.text.5": "Cuantifica el número de veces que la señal de audio cruza el nivel de amplitud cero dentro de una ventana temporal especificada. <span>ZCR</span> aporta información sobre las características texturales de la señal y es muy sensible al 'ruido' en el audio; un ruido más alto tiende a aumentar el valor <span>ZCR</span>.",
    "section.implemented_algorithms.text": "El proyecto implementó y optimizó múltiples algoritmos de agrupamiento adaptados específicamente al ámbito musical:",
    "section.implemented_algorithms.text.1": "Implementado con optimizaciones específicas, incluida la inicialización <span>K-Means++</span> para mejorar la convergencia y reducir la sensibilidad a los puntos de partida aleatorios. Se utilizaron el método del codo y el análisis de silueta para determinar el número óptimo de clústeres (k). K-Means mostró consistencia y estabilidad en todas las configuraciones, con un rendimiento medio de 0,420 en la puntuación combinada.",
    "section.implemented_algorithms.text.2-1": "Configurado para identificar grupos de densidad variable, una característica especialmente útil para detectar subgéneros musicales y patrones atípicos. Se llevó a cabo una optimización sistemática de los parámetros épsilon (ϵ) y MinPts mediante búsqueda por cuadrícula.",
    "section.implemented_algorithms.text.2-2": "Conclusión principal: <span>DBSCAN</span> resultó ser el algoritmo más eficaz, ya que obtuvo la puntuación combinada más alta, 0,563, con 18 clústeres. Esta superioridad sugiere que los patrones musicales presentan características de densidad variable que se captan mejor con algoritmos basados en la densidad que con los métodos centroidales tradicionales.",
    "section.implemented_algorithms.text.3": "Implementado como una extensión jerárquica de <span>DBSCAN</span>. <span>HDBSCAN</span> permite la identificación automática de clústeres con densidades variables, eliminando la necesidad de especificar el parámetro ϵ. HDBSCAN obtuvo el segundo mejor resultado con una puntuación combinada de 0,458 (generando 5 clústeres).",
    "section.implemented_algorithms.text.4": "Implementado para modelar clústeres con formas gaussianas complejas. <span>GMM</span> incluía la capacidad de determinar automáticamente el número de componentes utilizando el criterio de información bayesiano (BIC) y el criterio de información de Akaike (AIC).",
    "section.combined_metrics.text.1": "Se estableció un marco de evaluación integral para cuantificar la calidad de la agrupación musical desde múltiples perspectivas, combinando métricas de agrupación tradicionales con evaluaciones específicas del dominio. Este marco dio como resultado una puntuación combinada, diseñada para equilibrar la coherencia interna (calidad) con la correspondencia externa (relevancia).",
    "section.combined_metrics.text.2": "La puntuación combinada se calcula utilizando la siguiente fórmula ponderada:",
    "section.combined_metrics.text.3": "Donde:",
    "section.combined_metrics.text.4": "sil (<span>Silhouette Score</span>): Una métrica de calidad intrínseca que mide qué tan bien cada punto de datos se asigna a su propio clúster y se separa de los clústeres vecinos. Representa el 40 % de la puntuación total. Las puntuaciones van de -1 a +1, donde los valores cercanos a +1 indican una asignación de intervalo.",
    "section.combined_metrics.text.5": "ari (<span>Adjusted Rand Index</span>): Una métrica extrínseca que mide la similitud entre las asignaciones de agrupación resultantes y los géneros musicales conocidos reales (las etiquetas reales del conjunto de datos GTZAN). Representa el 30 % de la puntuación total. Los valores ARI oscilan entre -0,5 y 1,0, donde 1,0 indica una agrupación perfecta.",
    "section.combined_metrics.text.6": "k_pen (K-Penalty Factor): Un factor basado en el número de clústeres (k_pen=n_clust/target_k) que contribuye a la adecuación del número de clústeres. Representa el 30 % de la puntuación total.",
    "section.combined_metrics.text.7": "Esta combinación ponderada proporciona una evaluación integral que captura tanto la coherencia interna de los grupos musicales como su correspondencia con las categorías de género establecidas, lo que la hace especialmente valiosa para el análisis automático de grandes catálogos musicales. <span>DBSCAN</span> obtuvo la puntuación combinada más alta, 0.563, con este marco.",    

    // Informe: ANPR Recognition
    "section.summary.text-2": "Se desarrolló un pipeline de <span>ANPR</span> 100 % <span>Python</span> para material de vídeo. Se integró <span>YOLOv8</span> para la detección de vehículos/matrículas, <span>SORT</span> para el seguimiento de vehículos y <span>EasyOCR</span> para un reconocimiento de texto robusto. El sistema asigna identificadores únicos a los vehículos en todos los fotogramas y resuelve la ambigüedad de las matrículas seleccionando el texto con la <span>puntuación de confianza OCR</span> más alta.",
    "section.environment.text-2": "El entorno es 100 % <span>Python</span>. Las herramientas clave incluyen el detector de objetos <span>YOLOv8</span> (<span>Ultralytics</span>), el algoritmo de seguimiento de objetos <span>SORT</span> y la biblioteca <span>EasyOCR</span> para el reconocimiento de texto. El procesamiento de imágenes utilizó <span>OpenCV</span> (<span>CV2</span>).",
    "sub.scope.text-2": "Sistema <span>ANPR</span> integral centrado en la detección, el seguimiento y la lectura de matrículas del Reino Unido (<span>LLNNLLL</span>) en vídeos de autopistas.",
    "sub.steps.text-2.1": "Carga de dos modelos <span>YOLOv8</span>: uno para la detección de vehículos (<span>COCO</span>) y otro para la detección de matrículas",
    "sub.steps.text-2.2": "Lectura de fotogramas de vídeo secuencialmente y detección de vehículos utilizando el modelo <span>COCO</span>",
    "sub.steps.text-2.3": "Implementación del seguimiento de objetos <span>SORT</span> para asignar identificadores únicos y persistentes a los vehículos detectados",
    "sub.steps.text-2.4": "Detección de matrículas y asociación de cada cuadro delimitador de matrícula con su respectivo coche rastreado",
    "sub.steps.text-2.5": "Recorte de la imagen de la placa y aplicación del preprocesamiento: conversión a escala de grises y umbralización",
    "sub.steps.text-2.6": "Lectura de texto utilizando <span>EasyOCR</span>; validación y corrección de confusiones comunes entre caracteres (por ejemplo, S/5, O/0)",
    "sub.steps.text-2.7": "Estructuración de los resultados (ID, cuadro delimitador, texto, puntuaciones) en un diccionario con el número de fotograma como clave",
    "sub.steps.text-2.8": "Escritura de los resultados completos estructurados en un archivo de salida <span>CSV</span> para su almacenamiento y visualización",
    "sub.data_sources.text-2": "Los datos primarios son un vídeo de una autopista con muchos coches, en el que se ve una vista muy frontal de los vehículos y las matrículas. El modelo de detección de matrículas se entrenó externamente utilizando un conjunto de datos vinculado.",
    "sub.data_gathering.text-2.1": "Los datos se recopilaron a partir de un archivo de vídeo de entrada (<span>sample.mp4</span>) leyendo los fotogramas secuencialmente con <span>OpenCV</span>/<span>CV2</span>. Se utilizaron dos modelos de detección de objetos distintos por fotograma: un modelo <span>COCO</span> preentrenado para detectar vehículos en general (como coches, autobuses y camiones) y un modelo <span>YOLOv8</span> entrenado a medida para detectar específicamente las matrículas.",
    "sub.data_gathering.text-2.2": "Se aplicó el algoritmo <span>SORT</span> a las detecciones de vehículos para recopilar datos de seguimiento persistentes, asignando identificadores únicos que identifican al vehículo en múltiples fotogramas.",
    "sub.data_gathering.text-2.3": "Para el texto de la matrícula, se recortó la imagen de la matrícula, se preprocesó (se convirtió a escala de grises y se aplicó un umbral) para simplificar la imagen y, a continuación, se recopilaron el texto y la puntuación de confianza utilizando la biblioteca <span>EasyOCR</span>. A continuación, estos datos brutos de detección y <span>OCR</span> se filtraron por vehículos, se asociaron a una identificación de coche, se validaron según el formato específico del Reino Unido (dos letras, dos números, tres letras) y se estructuraron en un diccionario con el número de fotograma como clave antes de la salida final a un <span>archivo CSV</span>. Los datos del cuadro delimitador que faltaban en los fotogramas en los que no se había leído correctamente la matrícula se trataron mediante interpolación de datos externos para garantizar una visualización estable.",    

    // Informe: Medical Chatbot
    "section.summary.text-3": "Se implementó un chatbot médico integral utilizando un pipeline de <span>Retrieval-Augmented Generation</span> (<span>RAG</span>) y datos propios (The G Encyclopedia of Medicine). El sistema ofrece sugerencias para el diagnóstico, la medicación y el tratamiento. Se ha creado utilizando <span>Python</span>, <span>LangChain</span> y <span>Pinecone Vector DB</span> modulares, y se ha integrado con una interfaz de usuario <span>Flask</span> funcional.",
    "section.environment.text-3": "<span>Python</span> (programación modular), <span>LangChain</span> (marco generativo), <span>Pinecone</span> (base de datos vectorial basada en la nube), <span>Gemini AI LLM</span>, <span>Hugging Face</span> (modelos de incrustación, 384 dimensiones), <span>Flask</span> (interfaz de usuario), <span>Git</span>/<span>GitHub</span> (control de versiones), <span>PyPDFLoader</span> y un divisor de texto recursivo.",
    "sub.scope.text-3": "Se desarrolló el sistema <span>RAG</span> utilizando <span>Python</span>, <span>LangChain</span>, <span>Pinecone</span>, <span>Gemini AI</span>, <span>Hugging Face</span> y <span>Flask</span> para sugerencias médicas.",
    "sub.steps.text-3.1": "Creación de un entorno virtual <span>Python</span> y configuración de las dependencias necesarias que figuran en el archivo requirements.txt",
    "sub.steps.text-3.2": "Creación de una estructura de carpetas modular y robusta para mantener una base de código organizada y escalable",
    "sub.steps.text-3.3": "Extracción de todo el contenido del documento del PDF médico utilizando <span>PyPDFLoader</span>",
    "sub.steps.text-3.4": "División del texto extraído en 7020 fragmentos (size 500, overlap 20) utilizando un divisor de texto",
    "sub.steps.text-3.5": "Utilización de un modelo de incrustación <span>Hugging Face</span> para convertir fragmentos de texto en vectores de 384 dimensiones",
    "sub.steps.text-3.6": "Almacenamiento de los vectores en una base de datos vectorial Pinecone basada en la nube para crear la base de conocimientos/índice semántico",
    "sub.steps.text-3.7": "Inicialización de <span>GeminiAI LLM</span> y vinculación con el índice <span>Pinecone</span> utilizando la cadena <span>RAG</span>",
    "sub.steps.text-3.8": "Desarrollo de una interfaz de usuario funcional y visualmente atractiva utilizando <span>Flask</span> (marco de trabajo <span>Python</span>), <span>HTML</span>, <span>CSS</span> y <span>JavaScript</span>",
    "sub.steps.text-3.9": "Implementación del endpoint de la aplicación (<span>app.py</span>) para la preparación de la producción y la planificación del despliegue en la nube",
    "sub.data_sources.text-3": "La fuente del conjunto de datos personalizado es The G Encyclopedia of Medicine (PDF de 4505 páginas). Contiene información médica exhaustiva que incluye enfermedades, diagnósticos, tratamientos y sugerencias de medicamentos.",
    "sub.data_gathering.text-3.1": "Los datos personalizados utilizados para el proyecto se obtuvieron de un libro médico completo, concretamente The G Encyclopedia of Medicine, que está disponible en formato PDF y tiene aproximadamente 4505 páginas. Este conjunto de datos patentado contiene información médica exhaustiva sobre todo tipo de enfermedades, técnicas de diagnóstico, planes de tratamiento adecuados y medicamentos recomendados.",
    "sub.data_gathering.text-3.2": "El primer paso en la recopilación y la ingesta de datos consistió en cargar el documento PDF utilizando la utilidad <span>PyPDFLoader</span> de <span>LangChain</span>. Una vez extraído todo el contenido, fue necesario preparar los datos para el <span>Large Language Model</span> (<span>LLM</span>), lo que requirió una operación de fragmentación debido a las limitaciones de tamaño de entrada fijas del <span>LLM</span>.",
    "sub.data_gathering.text-3.3": "Se empleó un divisor de texto recursivo para dividir el texto extraído en fragmentos más pequeños y manejables. Este proceso generó un total de 7020 fragmentos a partir del documento original. A continuación, estos fragmentos se convirtieron en incrustaciones vectoriales de 384 dimensiones utilizando un modelo de código abierto de la plataforma <span>Hugging Face</span>. Por último, estas incrustaciones se almacenaron en <span>Pinecone</span>, una base de datos vectorial basada en la nube, que sirve como base de conocimientos permanente y escalable para el sistema <span>RAG</span>.",

    // Informe: Road Accident
    "section.data_modeling": "Modelado de datos, medidas y esquema",
    "section.summary.text-4": "Este proyecto se centró en el desarrollo de un panel dinámico e interactivo de <span>Power BI</span> de principio a fin para el análisis de accidentes de tráfico. El objetivo principal era aprovechar los datos de accidentes de tráfico de 2021 y 2022 para obtener información crítica. El panel se diseñó para satisfacer los requisitos específicos del cliente, incluido el cálculo de los <span>KPI</span> principales, como el total de víctimas, el total de accidentes y el crecimiento interanual. Los <span>KPI</span> secundarios consistían en analizar las víctimas en función de la gravedad (mortales, graves, leves), los tipos de vehículos, los tipos de carreteras, la ubicación de las zonas (urbanas/rurales) y las condiciones de iluminación (día/noche). La visualización también tenía como objetivo identificar los puntos negros de accidentes por ubicación.",
    "section.environment.text-4": "Este proyecto utilizó únicamente la versión gratuita de <span>Power BI</span>.",
    "sub.scope.text-4": "Desarrollo integral de un panel interactivo utilizando <span>Power BI</span>, <span>Power Query</span> y <span>DAX</span> para analizar dos años de datos sobre accidentes de tráfico.",
    "sub.steps.text-4.1": "Conexión de datos sin procesar de <span>Excel</span> (307 000 filas) a <span>Power BI Desktop</span>",
    "sub.steps.text-4.2": "Limpieza de los datos en <span>Power Query Editor</span> corrigiendo errores tipográficos (por ejemplo, sustituyendo 'fetal' por 'fatal')",
    "sub.steps.text-4.3": "Creación de una <span>Calendar Table</span> personalizada utilizando <span>DAX</span> para funciones de <span>Time Intelligence</span>",
    "sub.steps.text-4.4": "Establecimiento de una relación uno a muchos entre la <span>Calendar Table</span> y la tabla de datos principal",
    "sub.steps.text-4.5": "Creación de medidas complejas <span>DAX</span> para cálculos de crecimiento del <span>Current Year</span> (<span>YTD</span>), <span>Previous Year</span> y <span>Year-on-Year</span>",
    "sub.steps.text-4.6": "Creación y formato de diversas visualizaciones (<span>tarjetas KPI</span>, <span>gráfico de área</span>, <span>gráficos de donut</span>, <span>gráfico de barras</span> y <span>mapa</span>)",
    "sub.steps.text-4.7": "Implementación de <span>Segmentadores</span> (superficie de la carretera, condiciones meteorológicas) para el filtrado dinámico",
    "sub.data_sources.text-4": "Los datos brutos utilizados para este proyecto eran un archivo <span>Excel</span>. Este archivo sirvió como base de datos y contenía aproximadamente 307 000 filas y 21 columnas.",
    "sub.data_gathering.text-4": "El archivo <span>Excel</span> se puede consultar en <a href='https://www.data.gov.uk/dataset/cb7ae6f0-4be6-4935-9277-47e5ce24a11f/road-accidents-safety-data'>Road Safety Data</a>.",
    "sub.data_modeling": "Modelado de datos",
    "sub.dax_measures": "Medidas DAX",

    // Informe: Netflix Analysis
    "section.solutions": "Soluciones", 
    "section.summary.text-5": "Análisis avanzado de <span>SQL</span> de 8807 títulos de Netflix, resolviendo 15 problemas empresariales complejos. La metodología consistió en configurar una base de datos <span>PostgreSQL</span>, definir el esquema, manipular campos de texto complejos utilizando funciones de matriz y cadena (<span>UNNEST</span>, <span>STRING_TO_ARRAY</span>) y aplicar funciones de ventana.",
    "section.environment.text-5": "Las herramientas principales utilizadas fueron <span>PostgreSQL</span> para la base de datos y las consultas, con <span>PG Admin 4</span> como interfaz de gestión. La inspección inicial de los datos se realizó en <span>Excel</span>. El proyecto final se publicó en <span>GitHub</span>.",
    "sub.scope.text-5": "Resolución de 15 problemas empresariales de nivel medio-avanzado utilizando consultas complejas <span>SQL</span> en 8807 registros de Netflix.",
    "sub.steps.text-5.1": "Adquisición del conjunto de datos 'Netflix movies and TV shows' de la plataforma <span>Kaggle</span>",
    "sub.steps.text-5.2": "Realización de una exploración inicial de los datos en <span>Excel</span> para verificar los tipos y longitudes de las columnas",
    "sub.steps.text-5.3": "Creación de la base de datos y definición del esquema de la tabla en <span>PostgreSQL</span> utilizando <span>PG Admin 4</span>",
    "sub.steps.text-5.4": "Definición precisa de tipos de datos, cálculo de los límites <span>VARCHAR</span> para columnas de texto largo",
    "sub.steps.text-5.5": "Importación de los datos, solucionando los errores de importación corrigiendo la longitud <span>VARCHAR</span>",
    "sub.steps.text-5.6": "Confirmación de importación exitosa, verificando la existencia de un total de 8.807 registros",
    "sub.steps.text-5.7": "Desarrollo de soluciones complejas <span>SQL</span> para 15 problemas empresariales específicos",
    "sub.steps.text-5.8": "Uso de técnicas avanzadas como <span>UNNEST</span> para dividir columnas con múltiples valores (países, reparto)",
    "sub.steps.text-5.9": "Publicación del proyecto documentado y las soluciones de código en un repositorio de <span>GitHub</span>",
    "sub.data_sources.text-5": "El conjunto de datos, titulado 'Netflix movies and TV shows', se descargó de <span>Kaggle</span>. Contiene 8808 registros (títulos) con detalles sobre el ID del programa, el tipo (película/serie), el director, el reparto, el país, la fecha de estreno, la clasificación, la duración, el género y las descripciones.",
    "sub.data_gathering.text-5.1": "El proceso de recopilación de datos comenzó con la localización y descarga del conjunto de datos necesario, 'Netflix movies and TV shows', del sitio web <span>Kaggle</span>. Este conjunto de datos se proporcionó como un archivo comprimido (zip), que posteriormente se descomprimió. Enlace <a href='https://www.kaggle.com/datasets/shivamb/netflix-shows'>[AQUÍ]</a>.",
    "sub.data_gathering.text-5.2": "Tras la descarga, el archivo se abrió en <span>Excel</span> para realizar una exploración inicial crítica. Esta fase fue esencial para inspeccionar las características de los datos, especialmente la longitud potencial de los campos de texto, como el título, el director, el reparto y las descripciones. La comprobación reveló que ciertas columnas contenían cadenas de caracteres extremadamente largas (por ejemplo, director hasta 208 caracteres, reparto hasta 771 caracteres y descripción hasta 250 caracteres), lo que influyó directamente en el posterior diseño del esquema de la base de datos. Se confirmó que el conjunto de datos tenía un total de 8808 filas.",
    "sub.data_gathering.text-5.3": "El siguiente paso consistió en configurar la base de datos de destino en <span>PostgreSQL</span> y definir la estructura de la tabla. Durante la creación del esquema, se establecieron los límites <span>VARCHAR</span> adecuados para todas las columnas basándose en el análisis de <span>Excel</span> para evitar errores de truncamiento. Posteriormente, los datos se importaron al entorno <span>PostgreSQL</span> a través de <span>PG Admin 4</span>. El primer intento de importación falló debido a un límite <span>VARCHAR</span> insuficiente definido para la columna «listed in» (género). Esto se resolvió utilizando el comando <span>DROP TABLE</span>, aumentando el límite de la columna (de 25 a 100 caracteres), recreando la tabla y volviendo a ejecutar el proceso de importación con éxito. Esto garantizó la disponibilidad de los 8807 registros finales para su análisis.",
    "sub.solution.code": "Código",
    "sub.solution.result": "Resultado",
    "sub.solution.title-5.1": "1. Cuenta el número de películas frente al número de series de televisión",
    "sub.solution.title-5.2": "2. Encuentra la calificación más común para películas y programas de televisión",
    "sub.solution.title-5.3": "3. Enumera todas las películas estrenadas en un año específico (por ejemplo, 2020)",
    "sub.solution.title-5.4": "4. Encuentra los 5 países con más contenido en Netflix",
    "sub.solution.title-5.5": "5. Identifica la película más larga",
    "sub.solution.title-5.6": "6. Encuentra contenido añadido en los últimos 5 años",
    "sub.solution.title-5.7": "7. Encuentra todas las películas/series de televisión del director 'Rajiv Chilaka'",
    "sub.solution.title-5.8": "8. Enumera todos los programas de televisión con más de 5 temporadas",
    "sub.solution.title-5.9": "9. Cuenta el número de elementos de contenido en cada género",
    "sub.solution.title-5.10": "10. Encuentra cada año y el promedio de lanzamientos de contenido en India en Netflix. Devuelve los 5 años con el promedio más alto de lanzamientos de contenido",
    "sub.solution.title-5.11": "11. Enumera todas las películas que son documentales",
    "sub.solution.title-5.12": "12. Encuentra todo el contenido sin director",
    "sub.solution.title-5.13": "13. Averigua en cuántas películas ha aparecido el actor 'Salman Khan' en los últimos 10 años",
    "sub.solution.title-5.14": "14. Encuentra los 10 actores que han aparecido en el mayor número de películas producidas en la India",
    "sub.solution.title-5.15": "15. Clasifica el contenido en función de la presencia de las palabras clave 'matar' y 'violencia' en el campo de descripción. Etiqueta el contenido que contenga estas palabras clave como 'Malo' y el resto del contenido como 'Bueno'. Cuenta cuántos elementos entran en cada categoría",
  }
};
